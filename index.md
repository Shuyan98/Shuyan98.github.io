<table border="0">
  <tr>
    <td width="75%">
      <h1>Shuyan Li</h1>
      <p><b>Lecturer/Assistant Professor</b></p>
      <p><b>School of EEECS, Queen's University Belfast</b></p>
      <p><b>Email: shuyan.li@qub.ac.uk</b></p>
    </td>
    <td width="25%">
      <img src="/IMG_1437.jpg" width="100%">  
    </td>
  </tr>
</table>


# Biography
             

I am currently a Lecturer in the School of Electronics, Electrical Engineering and Computer Science (EEECS) at Queen's University Belfast. Prior to this, I worked as a Postdoctoral Research Associate in the Department of Engineering at the University of Cambridge, collaborating with Prof. <a href="http://www.eng.cam.ac.uk/profiles/ib340">Ioannis Brilakis</a>. In Jan. 2022, I got my doctor's degree in the Department of Automation at Tsinghua University, <a href="http://ivg.au.tsinghua.edu.cn/index.php">Intelligent Vision Group(IVG)</a>. I was supervised by Prof. <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/"> Jiwen Lu </a>, Prof. <a href="http://www.au.tsinghua.edu.cn/info/1110/1583.htm"> Jie Zhou </a> and Prof. <a href="https://www.sigs.tsinghua.edu.cn/lx/"> Xiu Li </a>. I am broadly interested in computer vision and AI for science. My current research focuses on representation learning, video understanding, construction digital twin.

  
# News
2024-06: I provided a talk on “Connecting Vision and Text for Video Analysis" at Computer Vision Symposium, Queen’s University Belfast, UK.

2024-03: I delivered a guest lecture for the MSc program in Digital Innovation in Built Asset Management at University College London.

2023-04: I provided a talk on “Unsupervised Learning for Visual Computing" at Department of Computer Science, University of Sheffield, UK.

2023-02: 3 papers on domain adaptation, object detection and multi-modal learning were accepted by <a href="https://2023.ieeeicassp.org">ICASSP'2023</a>.

2023-01: My doctorate thesis was awarded as Excellent Doctorate Dissertation by <a href="https://saai.net.cn/2711.html"> ShenZhen Association for Artificial Intelligence</a> (3 people awarded per annual).

2023-01: I gave a seminar talk at Division D, Department of Engineering at University of Cambridge to introduce unsupervised learning for digital twins. Thanks Prof. Ioannis Brilakis for the invitation!

  
# Publications
<table border="0">
 <tr>
            <td width="25%">
              <img style="width:100%;max-width:100%" src="A2SFOD.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Adversarial Alignment for Source Free Object Detection</papertitle>
              <br>
              Qiaosong Chu, <strong>Shuyan Li</strong>, Guangyi Chen, Kai Li and Xiu Li
              <br>
              <em>Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2301.04265.pdf">[PDF]</a> 
              <a href="https://youtu.be/omskABZs6Vo">[Video]</a> 
              <a href="https://github.com/ChuQiaosong">[Code]</a>
              <br>
              <p></p>
              <p> We propose an adversarial learning based source free object detection method.</p>
            </td>
</tr>
</table> 

<table border="0">
 <tr>
            <td width="25%">
              <img style="width:100%;max-width:100%" src="SNPH.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Structure-adaptive Neighborhood Preserving Hashing for Scalable Video Search</papertitle>
              <br>
              <strong>Shuyan Li</strong>, Xiu Li, Jiwen Lu and Jie Zhou
              <br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)</em>, 2021
              <br>
              <a href="Structure-adaptive Neighborhood Preserving Hashing for Scalable Video Search.pdf">[PDF]</a>
              <br>
              <p></p>
              <p> This is the journal version of NPH. Compared with NPH, we further develop an encoding network that can capture the hierachical structure of a video.</p>
            </td>
</tr>
</table> 

<table border="0">
 <tr>
            <td width="25%">
              <img style="width:100%;max-width:100%" src="bth.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Self-supervised Video Hashing via Bidirectional Transformers</papertitle>
              <br>
              <strong>Shuyan Li</strong>, Xiu Li, Jiwen Lu and Jie Zhou
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2021
              <br>
              <a href="Self-supervised Video Hashing via Bidirectional Transformers.pdf">[PDF]</a> <a href="https://github.com/Shuyan98/BTH">[Code]</a> 
              <br>
              <p></p>
              <p>We propose a self-supervised learning framework to capture bidirectional correlations among videos based on transformers.</p>
            </td>
</tr>
</table>  

<table border="0">
 <tr>
            <td width="25%">
              <img style="width:100%;max-width:100%" src="nph.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Neighborhood Preserving Hashing for Scalable Video Retrieval</papertitle>
              <br>
              <strong>Shuyan Li</strong>, Zhixiang Chen, Jiwen Lu, Xiu Li, and Jie Zhou
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2019
              <br>
              <a href="Neighborhood Preserving Hashing for Scalable Video Retrieval.pdf">[PDF]</a>  
              <br>
              <p></p>
              <p>We learn video hash functions via exploiting the neighborhood structure among videos.</p>
            </td>
</tr>
</table>
  
<table border="0">
 <tr>
            <td width="25%">
              <img style="width:100%;max-width:100%" src="Uvvh2.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Unsupervised Variational Video Hashing with 1D-CNN-LSTM Networks</papertitle>
              <br>
              <strong>Shuyan Li</strong>, Zhixiang Chen, Xiu Li, Jiwen Lu, and Jie Zhou
              <br>
              <em>IEEE Transactions on Multimedia (<strong>TMM</strong>)</em>, 2020
              <br>
              <a href="Unsupervised variational video hashing with 1D-CNN-LSTM Networks.pdf">[PDF]</a>
              <br>
              <p></p>
              <p>We propose a variational mechanism to learn robust video hash representation. </p>
            </td>
</tr>
</table>

# Teaching
Module owner, CSC1025 Procedural programming, School of EEECS, Queen's University Belfast, 2024.

Instructor, Digital Twin Workshop, University of Cambridge, 2024.

Module co-designer, <a href="https://teaching.eng.cam.ac.uk/content/engineering-tripos-part-iib-4d4-digital-construction-2024-25"> 4D4: Digital Construction</a>, University of Cambridge, 2023.

Demonstrator & Marking, <a href="http://teaching.eng.cam.ac.uk/content/engineering-tripos-part-iia-3f8-inference-2019-20"> 3F8: Inference</a>, Department of Engineering, University of Cambridge, Lent term 2023
  
TA, Computer culture basis, awarded as "Outstanding TA", Tsinghua University, Fall 2020

Teacher, Music, Central elementary school in Huangtu Town, Guizhou Province, Summer 2021

# Academic Services

<b>Program chair:</b> BMVC2024 Workshop - DIFA: Deep Learning-based Image Fusion and Its Applications

<b>Conference Reviewer:</b> AAAI, ICASSP, ICME, PRCV, WACV, ICIP, etc.

<b>Journal Reviewer:</b>  IEEE TPAMI, IEEE/ACM TASLP, IEEE TIP, IEEE TMM, IEEE TCSVT, PR, Neuralcomputing, etc.

&copy; Shuyan Li | Last updated: Oct., 2024

